#!/usr/bin/env python3
"""
Comparison tool to check if OCR outputs match ground truth transcriptions.
Compares transcription files generated by inference_all.py with spec_dict.json files.
"""

import os
import json
import re
import argparse
import yaml
from collections import Counter, defaultdict
from pathlib import Path


def extract_numbers_from_text(text, expected_patterns=None):
    """
    Extract numbers with units from text using regex patterns.
    
    Strategy:
    1. Find reliable connected patterns first (e.g., "1150kg", "575kpa")
    2. For any missing expected patterns, search for separated pieces
    
    Handles common OCR errors:
    - 5 ↔ s confusion (e.g., "s7s kPa" → "575kpa", "14s0 kg" → "1450kg")
    - Unit recognition errors:
      * PS1 → PSI normalization
      * P5I → PSI (5 instead of S)
      * P51 → PSI (5 instead of S, 1 instead of I)
      * lb5 → lbs (5 instead of s)
    - Various spacing formats (e.g., "575kpa", "575 kPa")
    - Separated numbers and units using targeted search for missing patterns
    
    Returns normalized format: ["1450kg", "3195lbs", "575kpa", "83psi"]
    """
    if not text:
        return []
    
    # Convert to lowercase for case-insensitive matching
    text = text.lower()
    
    # Step 1: Get connected patterns first (most reliable)
    connected_results = extract_connected_numbers_units(text)
    
    # Step 2: If we have expected patterns, supplement with separated search
    if expected_patterns:
        # Keep all connected/spaced results - they're reliable
        # Only use expected patterns to look for missing ones via separated search
        missing_patterns = find_missing_patterns(connected_results, expected_patterns)
        if missing_patterns:
            separated_results = extract_missing_separated_patterns(text, missing_patterns)
            return connected_results + separated_results
        return connected_results
    
    return connected_results


def find_missing_patterns(found_patterns, expected_patterns):
    """
    Find which expected patterns are missing from the found patterns.
    """
    found_set = set(found_patterns)
    expected_set = set(expected_patterns) if expected_patterns else set()
    missing = expected_set - found_set
    return list(missing)


def extract_missing_separated_patterns(text, missing_patterns):
    """
    For each missing pattern, look for its number and unit as separate tokens.
    Only creates pairs if both the exact number and unit are found separately.
    """
    if not missing_patterns:
        return []
    
    # Split text into tokens
    tokens = re.findall(r'\b\w+\b', text.lower())
    
    # Define unit patterns to look for (with OCR error handling)
    unit_patterns = {
        'kg': r'^kg$',
        'lbs': r'^(lbs?|lb5)$',
        'kpa': r'^kpa$',
        'psi': r'^(psi|ps1|p5i|p51)$',
    }
    
    found_separated = []
    
    for missing_pattern in missing_patterns:
        # Extract number and unit from the missing pattern
        match = re.match(r'^(\d+(?:\.\d+)?)([a-z]+)$', missing_pattern.lower())
        if not match:
            continue
            
        target_number = match.group(1)
        target_unit = match.group(2)
        
        # Look for the exact number as a standalone token
        number_found = False
        for token in tokens:
            # Check if token matches the target number (with OCR error handling)
            normalized_token = token.replace('s', '5')  # Handle s↔5 confusion
            try:
                if float(normalized_token) == float(target_number):
                    number_found = True
                    break
            except ValueError:
                continue
        
        # Look for the unit as a standalone token
        unit_found = False
        if target_unit in unit_patterns:
            pattern = unit_patterns[target_unit]
            for token in tokens:
                if re.match(pattern, token):
                    unit_found = True
                    break
        
        # If both number and unit found separately, create the pair
        if number_found and unit_found:
            # Format consistently
            if target_unit == 'lbs':
                found_separated.append(f"{int(float(target_number))}lbs")
            else:
                found_separated.append(f"{int(float(target_number))}{target_unit}")
    
    return found_separated


def extract_connected_numbers_units(text):
    """
    Extract numbers with units using regex patterns for both connected and spaced text.
    Returns list of found numbers and updates matched_positions.
    """
    
    # Patterns for different number formats with units (both connected and with spaces)
    patterns = [
        # Connected patterns (no spaces)
        r'\b(\d+(?:\.\d+)?)kg\b',      # kg (e.g., 1450kg)
        r'\b(\d+(?:\.\d+)?)lbs?\b',    # lbs/lb (e.g., 3000lbs)
        r'\b(\d+(?:\.\d+)?)kpa\b',     # kPa (e.g., 575kpa)
        r'\b(\d+(?:\.\d+)?)psi\b',     # PSI (e.g., 83psi)
        r'\b(\d+(?:\.\d+)?)ps1\b',     # PS1 (OCR error for PSI)
        
        # Spaced patterns (with spaces)
        r'\b(\d+(?:\.\d+)?)\s+kg\b',      # kg with space (e.g., 1450 kg)
        r'\b(\d+(?:\.\d+)?)\s+lbs?\b',    # lbs/lb with space (e.g., 3000 lbs)
        r'\b(\d+(?:\.\d+)?)\s+kpa\b',     # kPa with space (e.g., 575 kpa)
        r'\b(\d+(?:\.\d+)?)\s+psi\b',     # PSI with space (e.g., 83 psi)
        r'\b(\d+(?:\.\d+)?)\s+ps1\b',     # PS1 with space (OCR error for PSI)
        
        # OCR confusion patterns: 5 ↔ s (allow s at any position in number) - connected
        r'\b([s\d]*[s\d]+(?:\.\d+)?)kg\b',      # kg with 's' instead of '5' (e.g., 14s0kg, s60kg, 1s60kg)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)lbs?\b',    # lbs with 's' instead of '5' (e.g., 319slbs, s000lbs)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)kpa\b',     # kPa with 's' instead of '5' (e.g., s7skpa, 57skpa)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)psi\b',     # PSI with 's' instead of '5' (e.g., 8spsi, s3psi)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)ps1\b',     # PS1 with 's' instead of '5'
        
        # OCR confusion patterns: 5 ↔ s (allow s at any position in number) - spaced
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+kg\b',      # kg with 's' instead of '5' and space (e.g., 14s0 kg)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+lbs?\b',    # lbs with 's' instead of '5' and space (e.g., 319s lbs)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+kpa\b',     # kPa with 's' instead of '5' and space (e.g., s7s kpa)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+psi\b',     # PSI with 's' instead of '5' and space (e.g., 8s psi)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+ps1\b',     # PS1 with 's' instead of '5' and space
        
        # OCR confusion patterns: 5 ↔ s in units themselves - connected
        r'\b(\d+(?:\.\d+)?)p5i\b',     # P5I (OCR error for PSI: 5 instead of S)
        r'\b(\d+(?:\.\d+)?)p51\b',     # P51 (OCR error for PSI: 5 instead of S, 1 instead of I)
        r'\b(\d+(?:\.\d+)?)lb5\b',     # lb5 (OCR error for lbs: 5 instead of s)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)p5i\b',     # P5I with 's' in number
        r'\b([s\d]*[s\d]+(?:\.\d+)?)p51\b',     # P51 with 's' in number
        r'\b([s\d]*[s\d]+(?:\.\d+)?)lb5\b',     # lb5 with 's' in number
        
        # OCR confusion patterns: 5 ↔ s in units themselves - spaced
        r'\b(\d+(?:\.\d+)?)\s+p5i\b',     # P5I with space (OCR error for PSI: 5 instead of S)
        r'\b(\d+(?:\.\d+)?)\s+p51\b',     # P51 with space (OCR error for PSI: 5 instead of S, 1 instead of I)
        r'\b(\d+(?:\.\d+)?)\s+lb5\b',     # lb5 with space (OCR error for lbs: 5 instead of s)
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+p5i\b',     # P5I with 's' in number and space
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+p51\b',     # P51 with 's' in number and space
        r'\b([s\d]*[s\d]+(?:\.\d+)?)\s+lb5\b',     # lb5 with 's' in number and space
    ]

    found_numbers = []
    matched_positions = set()  # Track what we've already matched
    
    for pattern in patterns:
        matches = re.finditer(pattern, text)  # Use finditer to get positions
        for match_obj in matches:
            match_text = match_obj.group(1)
            start_pos = match_obj.start()
            end_pos = match_obj.end()
            
            # Skip if this position range overlaps with already matched text
            position_range = set(range(start_pos, end_pos))
            if position_range & matched_positions:
                continue
            
            # Skip matches that are purely letters (like "s" or "ss")
            if match_text.replace('.', '').isalpha():
                continue
                
            # Normalize 's' to '5' in the matched number
            normalized_match = match_text.replace('s', '5')
            
            # Skip if the result doesn't look like a valid number
            try:
                # Test if it's a valid number after conversion
                float(normalized_match)
            except ValueError:
                continue
            
            # Mark this position as matched
            matched_positions.update(position_range)
            
            # Reconstruct the full number with unit
            if 'kg' in pattern:
                found_numbers.append(f"{normalized_match}kg")
            elif 'lbs' in pattern or 'lb5' in pattern:
                found_numbers.append(f"{normalized_match}lbs")  # Normalize lb5 to lbs
            elif 'kpa' in pattern:
                found_numbers.append(f"{normalized_match}kpa")
            elif 'psi' in pattern or 'ps1' in pattern or 'p5i' in pattern or 'p51' in pattern:
                found_numbers.append(f"{normalized_match}psi")  # Normalize ps1, p5i, p51 to psi
    
    return found_numbers


def parse_transcription_file(file_path):
    """Parse a transcription file and extract detected text with scores."""
    transcriptions = []
    if not os.path.exists(file_path):
        return transcriptions
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    # Parse format: 'text' (score: 0.xxx)
                    match = re.match(r"'([^']+)'\s*\(score:\s*([\d.]+)\)", line)
                    if match:
                        text = match.group(1)
                        score = float(match.group(2))
                        transcriptions.append((text, score))
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
    
    return transcriptions


def extract_ground_truth_numbers(json_data):
    """Extract all numbers with units from JSON ground truth data."""
    all_text = ""
    for key, value in json_data.items():
        if isinstance(value, str):
            all_text += " " + value
    
    return extract_numbers_from_text(all_text)


def compare_folder(input_folder, output_folder):
    """Compare OCR results for a single folder against ground truth."""
    print(f"\n=== Analyzing folder: {os.path.basename(input_folder)} ===")
    
    # Read ground truth JSON
    json_path = os.path.join(input_folder, "spec_dict.json")
    if not os.path.exists(json_path):
        print(f"ERROR: Ground truth JSON not found at {json_path}")
        return None
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            ground_truth = json.load(f)
    except Exception as e:
        print(f"ERROR: Failed to read JSON file {json_path}: {e}")
        return None
    
    # Extract ground truth numbers
    gt_numbers = extract_ground_truth_numbers(ground_truth)
    gt_counter = Counter(gt_numbers)
    print(f"Ground truth numbers: {dict(gt_counter)}")

    # Process each transcription file
    transcription_files = [
        "center_img_transcription.txt",
        "left_img_transcription.txt", 
        "material_img_transcription.txt",
        "right_img_transcription.txt"
    ]
    
    all_detected_numbers = []
    results = {}
    
    for trans_file in transcription_files:
        trans_path = os.path.join(output_folder, trans_file)
        transcriptions = parse_transcription_file(trans_path)
        
        # Extract numbers from all transcribed text
        detected_text = " ".join([text for text, score in transcriptions])
        detected_numbers = extract_numbers_from_text(detected_text, gt_numbers)
        all_detected_numbers.extend(detected_numbers)
        
        results[trans_file] = {
            'transcriptions': transcriptions,
            'detected_numbers': detected_numbers
        }
        
        print(f"\n{trans_file}:")
        print(f"  Transcribed text: {[text for text, score in transcriptions]}")
        print(f"  Detected numbers: {detected_numbers}")
    
    # Compare overall results
    detected_counter = Counter(all_detected_numbers)
    print(f"\nDetected numbers (all files): {dict(detected_counter)}")
    
    # Check for matches and misses
    print(f"\n--- Comparison Results ---")
    all_correct = True
    
    for number, expected_count in gt_counter.items():
        detected_count = detected_counter.get(number, 0)
        if detected_count == expected_count:
            print(f"✓ {number}: Expected {expected_count}, Found {detected_count}")
        else:
            print(f"✗ {number}: Expected {expected_count}, Found {detected_count}")
            all_correct = False
    
    # Check for extra detections
    for number, detected_count in detected_counter.items():
        if number not in gt_counter:
            print(f"! Extra detection: {number} (found {detected_count} times)")
            all_correct = False
    
    return {
        'folder': os.path.basename(input_folder),
        'ground_truth': dict(gt_counter),
        'detected': dict(detected_counter),
        'all_correct': all_correct,
        'details': results
    }


def load_config(config_path):
    """Load configuration from YAML file."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        print(f"Error loading config file {config_path}: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description="Compare OCR outputs with ground truth")
    parser.add_argument('--config', '-c', default='comparetools/config.yaml',
                       help='Path to configuration YAML file (default: comparetools/config.yaml)')
    parser.add_argument('--input-base', 
                       help='Base directory containing input folders (overrides config)')
    parser.add_argument('--output-base',
                       help='Base directory containing output folders (overrides config)')
    parser.add_argument('--folder', help='Specific folder to analyze (overrides config)')
    
    args = parser.parse_args()
    
    # Load configuration
    config = load_config(args.config)
    if config is None:
        print(f"Failed to load config file: {args.config}")
        print("Please check the file exists and is valid YAML.")
        return
    
    # Command line arguments override config file
    input_base_path = args.input_base or config.get('input_base')
    output_base_path = args.output_base or config.get('output_base')
    specific_folder = args.folder or config.get('folder', '')
    
    if not input_base_path:
        print("ERROR: input_base must be specified in config file or via --input-base")
        return
    
    if not output_base_path:
        print("ERROR: output_base must be specified in config file or via --output-base")
        return
    
    input_base = Path(input_base_path)
    output_base = Path(output_base_path)
    
    if not input_base.exists():
        print(f"ERROR: Input base directory does not exist: {input_base}")
        return
    
    if not output_base.exists():
        print(f"Output base directory does not exist: {output_base}")
        print("Creating output directory...")
        try:
            output_base.mkdir(parents=True, exist_ok=True)
            print(f"Created output directory: {output_base}")
        except Exception as e:
            print(f"ERROR: Failed to create output directory: {e}")
            return
        print()
    
    # Get list of folders to process
    if specific_folder:
        folders_to_process = [specific_folder]
    else:
        folders_to_process = [d.name for d in input_base.iterdir() if d.is_dir()]
    
    print(f"Using configuration from: {args.config}")
    print(f"Input base: {input_base}")
    print(f"Output base: {output_base}")
    if specific_folder:
        print(f"Processing single folder: {specific_folder}")
    print(f"Processing {len(folders_to_process)} folders...")
    print()
    
    overall_results = []
    correct_count = 0
    
    for folder_name in sorted(folders_to_process):
        input_folder = input_base / folder_name
        output_folder = output_base / folder_name
        
        if not input_folder.exists():
            print(f"WARNING: Input folder does not exist: {input_folder}")
            continue
            
        if not output_folder.exists():
            print(f"WARNING: Output folder does not exist: {output_folder}")
            continue
        
        result = compare_folder(str(input_folder), str(output_folder))
        if result:
            overall_results.append(result)
            if result['all_correct']:
                correct_count += 1
    
    # Save detailed report if requested
    if config.get('save_detailed_report', False) and overall_results:
        report_file = config.get('report_file', 'comparison_report.json')
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(overall_results, f, indent=2, ensure_ascii=False)
            print(f"\nDetailed report saved to: {report_file}")
        except Exception as e:
            print(f"WARNING: Failed to save report: {e}")
    
    # Print summary
    print(f"\n{'='*60}")
    print(f"SUMMARY")
    print(f"{'='*60}")
    print(f"Total folders processed: {len(overall_results)}")
    print(f"Folders with all correct matches: {correct_count}")
    print(f"Accuracy: {correct_count}/{len(overall_results)} ({100*correct_count/len(overall_results):.1f}%)" if overall_results else "No results")
    
    # Print detailed results for incorrect folders
    incorrect_folders = [r for r in overall_results if not r['all_correct']]
    if incorrect_folders:
        print(f"\nFolders with incorrect matches:")
        for result in incorrect_folders:
            print(f"  - {result['folder']}")
            print(f"    Ground truth: {result['ground_truth']}")
            print(f"    Detected: {result['detected']}")


if __name__ == "__main__":
    main()
