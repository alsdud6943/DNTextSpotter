#!/usr/bin/env python3
"""
Comparison tool to check if OCR numeric outputs match ground truth transcriptions.
Compares only the numeric values, ignoring units (e.g., "575kpa" vs "575psi" both match for "575").
Compares transcription files generated by inference_all.py with spec_dict.json files.
"""

import os
import json
import re
import argparse
import yaml
import sys
from collections import Counter, defaultdict
from pathlib import Path


class OutputCapture:
    """Capture print output to both console and a log file."""
    
    def __init__(self, log_file=None):
        self.log_file = log_file
        self.log_content = []
        
    def print(self, *args, **kwargs):
        """Print to console and capture to log."""
        # Print to console
        print(*args, **kwargs)
        
        # Capture to log
        if self.log_file:
            # Convert print arguments to string like print() does
            sep = kwargs.get('sep', ' ')
            end = kwargs.get('end', '\n')
            output = sep.join(str(arg) for arg in args) + end
            self.log_content.append(output)
    
    def save_log(self):
        """Save captured output to log file."""
        if self.log_file and self.log_content:
            try:
                with open(self.log_file, 'w', encoding='utf-8') as f:
                    f.writelines(self.log_content)
                return True
            except Exception as e:
                print(f"WARNING: Failed to save log file: {e}")
                return False
        return False





def extract_numbers_from_text(text, expected_patterns=None):
    """
    Extract just the numeric values from text, ignoring units.
    Used for transcription text where units may be mis-transcribed.
    
    Strategy:
    1. Normalize all OCR-confused characters to digits (l/i→1, g→9, s→5, o→0)
    2. Extract all contiguous digit sequences
    3. Return the numeric values for comparison
    
    This simple approach handles all OCR confusions naturally:
    - "gookg" → "900k9" → extracts "900" and "9"
    - "s7s" → "575" → extracts "575"  
    - "14s0" → "1450" → extracts "1450"
    - "2335lds" → "2335105" → extracts "2335" and "105"
    
    Returns normalized numeric values: ["1450", "575", "900", "9"]
    """
    if not text:
        return []
    
    # Convert to lowercase for consistent processing
    text = text.lower()
    
    # Normalize OCR confusions to digits
    # Common OCR character confusions:
    # l, I -> 1
    # g -> 9  
    # s, S -> 5
    # o, O -> 0 (sometimes)
    normalized_text = text.replace('l', '1').replace('i', '1').replace('g', '9').replace('s', '5').replace('o', '0')
    
    # Extract all contiguous digit sequences (not requiring word boundaries)  
    digit_sequences = re.findall(r'\d+', normalized_text)
    
    # Convert to integers and back to strings to normalize (removes leading zeros)
    found_numbers = []
    for seq in digit_sequences:
        try:
            num_value = int(seq)
            # Only keep multi-digit numbers (single digits are usually OCR noise)
            if len(seq) > 1:  # Keep only numbers with 2+ digits
                found_numbers.append(str(num_value))
        except ValueError:
            continue
    
    return found_numbers


def extract_ground_truth_numbers(json_data):
    """Extract numeric values from JSON ground truth data without OCR normalization."""
    all_text = ""
    # for key, value in json_data.items():
    #     if isinstance(value, str):
    #         all_text += " " + value
    
    # Use only the "LOAD & PRESSURE" field for ground truth
    all_text = json_data.get("LOAD & PRESSURE", "")

    if not all_text:
        return []
    
    # Convert to lowercase for consistent processing
    all_text = all_text.lower()
    
    # Extract all contiguous digit sequences directly (no OCR normalization needed)
    # Ground truth is manually created and doesn't have OCR errors
    digit_sequences = re.findall(r'\d+', all_text)
    
    # Convert to integers and back to strings to normalize (removes leading zeros)
    found_numbers = []
    for seq in digit_sequences:
        try:
            num_value = int(seq)
            # Only keep multi-digit numbers for consistency with OCR extraction
            if len(seq) > 1:  # Keep only numbers with 2+ digits
                found_numbers.append(str(num_value))
        except ValueError:
            continue
    
    return found_numbers


def parse_transcription_file(file_path):
    """Parse a transcription file and extract detected text with scores."""
    transcriptions = []
    if not os.path.exists(file_path):
        return transcriptions
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    # Parse format: 'text' (score: 0.xxx)
                    match = re.match(r"'([^']+)'\s*\(score:\s*([\d.]+)\)", line)
                    if match:
                        text = match.group(1)
                        score = float(match.group(2))
                        transcriptions.append((text, score))
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
    
    return transcriptions


def compare_folder(input_folder, output_folder, output_capture=None):
    """Compare OCR results for a single folder against ground truth."""
    # Use output_capture if provided, otherwise use regular print
    out = output_capture if output_capture else type('', (), {'print': print})()
    
    out.print(f"\n=== Analyzing folder: {os.path.basename(input_folder)} ===")
    
    # Read ground truth JSON
    json_path = os.path.join(input_folder, "spec_dict.json")
    if not os.path.exists(json_path):
        out.print(f"ERROR: Ground truth JSON not found at {json_path}")
        return None
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            ground_truth = json.load(f)
    except Exception as e:
        out.print(f"ERROR: Failed to read JSON file {json_path}: {e}")
        return None
    
    # Extract ground truth numbers (just numeric values)
    gt_numbers = extract_ground_truth_numbers(ground_truth)
    gt_counter = Counter(gt_numbers)
    out.print(f"Ground truth numbers: {dict(gt_counter)}")

    # Process each transcription file
    transcription_files = [
        "center_img_transcription.txt",
        "left_img_transcription.txt", 
        "material_img_transcription.txt",
        "right_img_transcription.txt"
    ]
    
    all_detected_numbers = []
    results = {}
    
    for trans_file in transcription_files:
        trans_path = os.path.join(output_folder, trans_file)
        transcriptions = parse_transcription_file(trans_path)
        
        # Extract numbers from all transcribed text (just numeric values)
        detected_text = " ".join([text for text, score in transcriptions])
        detected_numbers = extract_numbers_from_text(detected_text)
        all_detected_numbers.extend(detected_numbers)
        
        results[trans_file] = {
            'transcriptions': transcriptions,
            'detected_numbers': detected_numbers
        }
        
        out.print(f"\n{trans_file}:")
        out.print(f"  Transcribed text: {[text for text, score in transcriptions]}")
        out.print(f"  Detected numbers: {detected_numbers}")
    
    # Compare overall results
    detected_counter = Counter(all_detected_numbers)
    out.print(f"\nDetected numbers (all files): {dict(detected_counter)}")
    
    # Check for matches and misses using substring matching
    out.print(f"\n--- Comparison Results (Numbers Only) ---")
    all_correct = True
    
    for number, expected_count in gt_counter.items():
        # Count how many detected numbers contain this ground truth number
        matches_found = 0
        matching_detections = []
        
        for detected_num, detected_count in detected_counter.items():
            if number in detected_num:  # Check if ground truth number is substring of detected
                matches_found += detected_count
                matching_detections.append(f"{detected_num}({detected_count}x)")
        
        if matches_found >= expected_count:
            if matching_detections:
                out.print(f"✓ {number}: Expected {expected_count}, Found {matches_found} in {', '.join(matching_detections)}")
            else:
                out.print(f"✓ {number}: Expected {expected_count}, Found {matches_found}")
        else:
            out.print(f"✗ {number}: Expected {expected_count}, Found {matches_found}")
            if matching_detections:
                out.print(f"    Partial matches: {', '.join(matching_detections)}")
            all_correct = False
    
    # Show extra detections that don't contain any ground truth numbers
    extra_detections = []
    for detected_num, detected_count in detected_counter.items():
        # Check if this detection contains any ground truth number
        contains_gt = any(gt_num in detected_num for gt_num in gt_counter.keys())
        if not contains_gt:
            extra_detections.append(f"{detected_num} (found {detected_count} times)")
    
    if extra_detections:
        out.print(f"ℹ Extra detections (no GT match): {', '.join(extra_detections)}")
    
    return {
        'folder': os.path.basename(input_folder),
        'ground_truth': dict(gt_counter),
        'detected': dict(detected_counter),
        'all_correct': all_correct,
        'details': results
    }


def load_config(config_path):
    """Load configuration from YAML file."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        print(f"Error loading config file {config_path}: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description="Compare OCR numeric outputs with ground truth (numbers only, ignoring units)")
    parser.add_argument('--config', '-c', default='comparetools/config.yaml',
                       help='Path to configuration YAML file (default: comparetools/config.yaml)')
    parser.add_argument('--input-base', 
                       help='Base directory containing input folders (overrides config)')
    parser.add_argument('--output-base',
                       help='Base directory containing output folders (overrides config)')
    parser.add_argument('--folder', help='Specific folder to analyze (overrides config)')
    
    args = parser.parse_args()
    
    # Load configuration
    config = load_config(args.config)
    if config is None:
        print(f"Failed to load config file: {args.config}")
        print("Please check the file exists and is valid YAML.")
        return
    
    # Setup output capture if detailed report is requested
    output_capture = None
    if config.get('save_detailed_report', False):
        log_file = config.get('log_file', 'comparison_log.txt')
        output_capture = OutputCapture(log_file)
        out = output_capture
    else:
        # Create a simple object that just uses regular print
        out = type('', (), {'print': print})()
    
    # Command line arguments override config file
    input_base_path = args.input_base or config.get('input_base')
    output_base_path = args.output_base or config.get('output_base')
    specific_folder = args.folder or config.get('folder', '')
    
    if not input_base_path:
        out.print("ERROR: input_base must be specified in config file or via --input-base")
        return
    
    if not output_base_path:
        out.print("ERROR: output_base must be specified in config file or via --output-base")
        return
    
    input_base = Path(input_base_path)
    output_base = Path(output_base_path)
    
    if not input_base.exists():
        out.print(f"ERROR: Input base directory does not exist: {input_base}")
        return
    
    if not output_base.exists():
        out.print(f"Output base directory does not exist: {output_base}")
        out.print("Creating output directory...")
        try:
            output_base.mkdir(parents=True, exist_ok=True)
            out.print(f"Created output directory: {output_base}")
        except Exception as e:
            out.print(f"ERROR: Failed to create output directory: {e}")
            return
        out.print()
    
    # Get list of folders to process
    if specific_folder:
        folders_to_process = [specific_folder]
    else:
        folders_to_process = [d.name for d in input_base.iterdir() if d.is_dir()]
    
    out.print(f"Using configuration from: {args.config}")
    out.print(f"Input base: {input_base}")
    out.print(f"Output base: {output_base}")
    if specific_folder:
        out.print(f"Processing single folder: {specific_folder}")
    out.print(f"Processing {len(folders_to_process)} folders...")
    out.print()
    
    overall_results = []
    correct_count = 0
    
    for folder_name in sorted(folders_to_process):
        input_folder = input_base / folder_name
        output_folder = output_base / folder_name
        
        if not input_folder.exists():
            out.print(f"WARNING: Input folder does not exist: {input_folder}")
            continue
            
        if not output_folder.exists():
            out.print(f"WARNING: Output folder does not exist: {output_folder}")
            continue
        
        result = compare_folder(str(input_folder), str(output_folder), output_capture)
        if result:
            overall_results.append(result)
            if result['all_correct']:
                correct_count += 1
    
    # Save detailed report if requested
    if config.get('save_detailed_report', False) and overall_results:
        report_file = config.get('report_file', 'comparison_report.json')
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(overall_results, f, indent=2, ensure_ascii=False)
            out.print(f"\nDetailed report saved to: {report_file}")
        except Exception as e:
            out.print(f"WARNING: Failed to save report: {e}")
    
    # Print summary
    out.print(f"\n{'='*60}")
    out.print(f"SUMMARY")
    out.print(f"{'='*60}")
    out.print(f"Total folders processed: {len(overall_results)}")
    out.print(f"Folders with all correct matches: {correct_count}")
    out.print(f"Accuracy: {correct_count}/{len(overall_results)} ({100*correct_count/len(overall_results):.1f}%)" if overall_results else "No results")
    
    # Print detailed results for incorrect folders
    incorrect_folders = [r for r in overall_results if not r['all_correct']]
    if incorrect_folders:
        out.print(f"\nFolders with incorrect matches:")
        for result in incorrect_folders:
            out.print(f"  - {result['folder']}")
            out.print(f"    Ground truth: {result['ground_truth']}")
            out.print(f"    Detected: {result['detected']}")
    
    # Save log file if output capture was used
    if output_capture and output_capture.save_log():
        log_file = config.get('log_file', 'comparison_log.txt')
        print(f"\nLog file saved to: {log_file}")


if __name__ == "__main__":
    main()
